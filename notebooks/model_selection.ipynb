{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e47e425e",
   "metadata": {},
   "source": [
    "# üèÜ S√âLECTION DU MOD√àLE FINAL\n",
    "## Comparaison des performances des mod√®les entra√Æn√©s\n",
    "\n",
    "Ce notebook compare les trois mod√®les entra√Æn√©s pour pr√©dire le **rendement du ma√Øs (yield)** :\n",
    "1. Ridge Regression (R√©gression Lin√©aire R√©gularis√©e)\n",
    "2. Random Forest Regressor\n",
    "3. Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdce98d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'base (Python 3.12.3)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25101b35",
   "metadata": {},
   "source": [
    "## 1. Chargement des donn√©es et pr√©paration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8753ab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des donn√©es\n",
    "df = pd.read_csv('../data/hvstat_africa_data_v1.0.csv')\n",
    "df_maize = df[df['product'].str.contains('maize|corn|ma√Øs', case=False, na=False)].copy()\n",
    "\n",
    "# Nettoyage des outliers\n",
    "mask = (\n",
    "    df_maize['area'].between(0.1, 50000) &\n",
    "    df_maize['production'].between(1, 50000) &\n",
    "    df_maize['yield'].between(0.1, 8)\n",
    ")\n",
    "df_clean = df_maize[mask].copy()\n",
    "df_clean = df_clean.dropna(subset=['yield', 'area', 'production'])\n",
    "\n",
    "# Standardisation syst√®me de production\n",
    "df_clean['system_simplified'] = 'other'\n",
    "sys_lower = df_clean['crop_production_system'].str.lower()\n",
    "df_clean.loc[sys_lower.str.contains('irrigated|water|dam|riverine', na=False), 'system_simplified'] = 'irrigated'\n",
    "df_clean.loc[sys_lower.str.contains('rainfed|dieri|recessional', na=False), 'system_simplified'] = 'rainfed'\n",
    "df_clean.loc[sys_lower.str.contains('commercial|mechanized|large_scale|lscf', na=False), 'system_simplified'] = 'commercial_mechanized'\n",
    "df_clean.loc[sys_lower.str.contains('traditional|communal|small|pastoral|sscf|a1|a2', na=False), 'system_simplified'] = 'traditional_small_scale'\n",
    "df_clean.loc[sys_lower.str.contains('all|none|or \\(ps\\)', na=False), 'system_simplified'] = 'general_unknown'\n",
    "\n",
    "print(f\"‚úÖ Dataset nettoy√©: {len(df_clean):,} observations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86727a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©paration des features\n",
    "features_cols = ['country_code', 'season_name', 'planting_month', 'harvest_month', 'area', 'system_simplified']\n",
    "X = df_clean[features_cols]\n",
    "y = df_clean['yield']\n",
    "\n",
    "# Encodage One-Hot\n",
    "X_encoded = pd.get_dummies(X, columns=['country_code', 'season_name', 'system_simplified'], drop_first=True)\n",
    "\n",
    "# Division Train/Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scaling pour Ridge Regression\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Train: {X_train.shape[0]} samples, Test: {X_test.shape[0]} samples\")\n",
    "print(f\"Features: {X_train.shape[1]} colonnes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9e8af4",
   "metadata": {},
   "source": [
    "## 2. Chargement des mod√®les entra√Æn√©s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2cfb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des mod√®les\n",
    "ridge_model = joblib.load('../ml_models_pkg/ridge_regression_model.pkl')\n",
    "rf_model = joblib.load('../ml_models_pkg/random_forest_model.pkl')\n",
    "gb_model = joblib.load('../ml_models_pkg/gb_model.pkl')\n",
    "\n",
    "print(\"‚úÖ Mod√®les charg√©s avec succ√®s!\")\n",
    "print(f\"  - Ridge Regression: alpha = {ridge_model.alpha}\")\n",
    "print(f\"  - Random Forest: {rf_model.n_estimators} arbres, max_depth = {rf_model.max_depth}\")\n",
    "print(f\"  - Gradient Boosting: {gb_model.n_estimators} arbres, learning_rate = {gb_model.learning_rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b9f0ef",
   "metadata": {},
   "source": [
    "## 3. √âvaluation comparative des mod√®les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b232d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, model_name, scaled=False):\n",
    "    \"\"\"√âvalue un mod√®le et retourne les m√©triques.\"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'Mod√®le': model_name,\n",
    "        'MAE (t/ha)': mae,\n",
    "        'RMSE (t/ha)': rmse,\n",
    "        'R¬≤ Score': r2,\n",
    "        'Predictions': y_pred\n",
    "    }\n",
    "\n",
    "# √âvaluation des trois mod√®les\n",
    "results = []\n",
    "results.append(evaluate_model(ridge_model, X_test_scaled, y_test, 'Ridge Regression'))\n",
    "results.append(evaluate_model(rf_model, X_test, y_test, 'Random Forest'))\n",
    "results.append(evaluate_model(gb_model, X_test, y_test, 'Gradient Boosting'))\n",
    "\n",
    "# Cr√©ation du tableau comparatif\n",
    "comparison_df = pd.DataFrame([{k: v for k, v in r.items() if k != 'Predictions'} for r in results])\n",
    "comparison_df = comparison_df.sort_values('R¬≤ Score', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä TABLEAU COMPARATIF DES PERFORMANCES\")\n",
    "print(\"=\"*70)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4196dac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des performances\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "colors = ['#3498db', '#2ecc71', '#e74c3c']\n",
    "models = ['Ridge Regression', 'Random Forest', 'Gradient Boosting']\n",
    "\n",
    "# R¬≤ Score\n",
    "r2_scores = [r['R¬≤ Score'] for r in results]\n",
    "bars1 = axes[0].bar(models, r2_scores, color=colors, edgecolor='black')\n",
    "axes[0].set_ylabel('R¬≤ Score')\n",
    "axes[0].set_title('R¬≤ Score (Plus √©lev√© = Meilleur)', fontweight='bold')\n",
    "axes[0].set_ylim(0, 1)\n",
    "for bar, score in zip(bars1, r2_scores):\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
    "                 f'{score:.4f}', ha='center', fontweight='bold')\n",
    "\n",
    "# MAE\n",
    "mae_scores = [r['MAE (t/ha)'] for r in results]\n",
    "bars2 = axes[1].bar(models, mae_scores, color=colors, edgecolor='black')\n",
    "axes[1].set_ylabel('MAE (tonnes/ha)')\n",
    "axes[1].set_title('MAE - Erreur Absolue Moyenne (Plus bas = Meilleur)', fontweight='bold')\n",
    "for bar, score in zip(bars2, mae_scores):\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                 f'{score:.4f}', ha='center', fontweight='bold')\n",
    "\n",
    "# RMSE\n",
    "rmse_scores = [r['RMSE (t/ha)'] for r in results]\n",
    "bars3 = axes[2].bar(models, rmse_scores, color=colors, edgecolor='black')\n",
    "axes[2].set_ylabel('RMSE (tonnes/ha)')\n",
    "axes[2].set_title('RMSE - Racine de l\\'Erreur Quadratique (Plus bas = Meilleur)', fontweight='bold')\n",
    "for bar, score in zip(bars3, rmse_scores):\n",
    "    axes[2].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                 f'{score:.4f}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../ml_models_pkg/model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"\\nüìà Graphique sauvegard√©: ml_models_pkg/model_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf45088",
   "metadata": {},
   "source": [
    "## 4. Analyse des pr√©dictions vs valeurs r√©elles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66fa5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphiques de pr√©dictions vs r√©alit√©\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "for i, (result, ax, color) in enumerate(zip(results, axes, colors)):\n",
    "    y_pred = result['Predictions']\n",
    "    ax.scatter(y_test, y_pred, alpha=0.5, color=color, edgecolor='none', s=20)\n",
    "    \n",
    "    # Ligne parfaite (y = x)\n",
    "    min_val, max_val = min(y_test.min(), y_pred.min()), max(y_test.max(), y_pred.max())\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], 'k--', lw=2, label='Pr√©diction parfaite')\n",
    "    \n",
    "    ax.set_xlabel('Valeurs r√©elles (t/ha)')\n",
    "    ax.set_ylabel('Pr√©dictions (t/ha)')\n",
    "    ax.set_title(f\"{result['Mod√®le']}\\nR¬≤ = {result['R¬≤ Score']:.4f}\", fontweight='bold')\n",
    "    ax.legend(loc='upper left')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../ml_models_pkg/predictions_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8608b85",
   "metadata": {},
   "source": [
    "## 5. Distribution des erreurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0924b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "for i, (result, ax, color) in enumerate(zip(results, axes, colors)):\n",
    "    y_pred = result['Predictions']\n",
    "    errors = y_test.values - y_pred\n",
    "    \n",
    "    ax.hist(errors, bins=50, color=color, edgecolor='black', alpha=0.7)\n",
    "    ax.axvline(x=0, color='red', linestyle='--', linewidth=2, label='Erreur nulle')\n",
    "    ax.axvline(x=errors.mean(), color='blue', linestyle='-', linewidth=2, label=f'Moyenne: {errors.mean():.3f}')\n",
    "    \n",
    "    ax.set_xlabel('Erreur (t/ha)')\n",
    "    ax.set_ylabel('Fr√©quence')\n",
    "    ax.set_title(f\"Distribution des erreurs - {result['Mod√®le']}\", fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../ml_models_pkg/error_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5484654",
   "metadata": {},
   "source": [
    "## 6. üèÜ S√âLECTION DU MOD√àLE FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b160974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©termination du meilleur mod√®le\n",
    "best_idx = np.argmax([r['R¬≤ Score'] for r in results])\n",
    "best_model_name = results[best_idx]['Mod√®le']\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üèÜ MOD√àLE FINAL S√âLECTIONN√â\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n‚úÖ Le mod√®le retenu est: {best_model_name}\")\n",
    "print(f\"\\nüìä Performances sur le jeu de test:\")\n",
    "print(f\"   ‚Ä¢ R¬≤ Score: {results[best_idx]['R¬≤ Score']:.4f}\")\n",
    "print(f\"   ‚Ä¢ MAE: {results[best_idx]['MAE (t/ha)']:.4f} t/ha\")\n",
    "print(f\"   ‚Ä¢ RMSE: {results[best_idx]['RMSE (t/ha)']:.4f} t/ha\")\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b08159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Justification du choix\n",
    "print(\"\\nüìù JUSTIFICATION DU CHOIX DU MOD√àLE\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Analyse comparative\n",
    "ridge_r2 = results[0]['R¬≤ Score']\n",
    "rf_r2 = results[1]['R¬≤ Score']\n",
    "gb_r2 = results[2]['R¬≤ Score']\n",
    "\n",
    "print(f\"\"\"\n",
    "1. **Ridge Regression** (R¬≤ = {ridge_r2:.4f})\n",
    "   - ‚úÖ Simple et interpr√©table\n",
    "   - ‚úÖ Rapide √† entra√Æner\n",
    "   - ‚ùå Performance limit√©e sur donn√©es non-lin√©aires\n",
    "\n",
    "2. **Random Forest** (R¬≤ = {rf_r2:.4f})\n",
    "   - ‚úÖ Robuste aux outliers\n",
    "   - ‚úÖ Capture les relations non-lin√©aires\n",
    "   - ‚úÖ Feature importance disponible\n",
    "   - ‚ùå Peut √™tre lent pour de gros datasets\n",
    "\n",
    "3. **Gradient Boosting** (R¬≤ = {gb_r2:.4f})\n",
    "   - ‚úÖ Souvent le plus pr√©cis\n",
    "   - ‚úÖ Optimise it√©rativement les erreurs\n",
    "   - ‚ùå Plus sensible au surapprentissage\n",
    "   - ‚ùå Plus lent √† entra√Æner\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\\nüéØ CONCLUSION: Le mod√®le {best_model_name} offre le meilleur compromis\")\n",
    "print(\"   entre performance pr√©dictive et g√©n√©ralisation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b64ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde du mod√®le final pour le d√©ploiement\n",
    "import shutil\n",
    "\n",
    "# Le mod√®le final sera utilis√© par l'API\n",
    "final_model_path = '../ml_models_pkg/final_model.pkl'\n",
    "\n",
    "if best_model_name == 'Ridge Regression':\n",
    "    joblib.dump(ridge_model, final_model_path)\n",
    "    joblib.dump(scaler, '../ml_models_pkg/final_scaler.pkl')\n",
    "    model_type = 'ridge'\n",
    "elif best_model_name == 'Random Forest':\n",
    "    joblib.dump(rf_model, final_model_path)\n",
    "    model_type = 'random_forest'\n",
    "else:\n",
    "    joblib.dump(gb_model, final_model_path)\n",
    "    model_type = 'gradient_boosting'\n",
    "\n",
    "# Sauvegarde des m√©tadonn√©es\n",
    "model_metadata = {\n",
    "    'model_type': model_type,\n",
    "    'model_name': best_model_name,\n",
    "    'r2_score': results[best_idx]['R¬≤ Score'],\n",
    "    'mae': results[best_idx]['MAE (t/ha)'],\n",
    "    'rmse': results[best_idx]['RMSE (t/ha)'],\n",
    "    'features': X_encoded.columns.tolist(),\n",
    "    'target': 'yield',\n",
    "    'training_samples': len(X_train),\n",
    "    'test_samples': len(X_test)\n",
    "}\n",
    "\n",
    "joblib.dump(model_metadata, '../ml_models_pkg/model_metadata.pkl')\n",
    "\n",
    "print(f\"\\n‚úÖ Mod√®le final sauvegard√©: {final_model_path}\")\n",
    "print(f\"‚úÖ M√©tadonn√©es sauvegard√©es: ../ml_models_pkg/model_metadata.pkl\")\n",
    "print(f\"\\nüöÄ Le mod√®le est pr√™t pour le d√©ploiement!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aae885",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e36501",
   "metadata": {},
   "source": [
    "## 7. R√©sum√© pour le rapport\n",
    "\n",
    "### Tableau r√©capitulatif des performances\n",
    "\n",
    "| Mod√®le | R¬≤ Score | MAE (t/ha) | RMSE (t/ha) |\n",
    "|--------|----------|------------|-------------|\n",
    "| Ridge Regression | voir ci-dessus | voir ci-dessus | voir ci-dessus |\n",
    "| Random Forest | voir ci-dessus | voir ci-dessus | voir ci-dessus |\n",
    "| Gradient Boosting | voir ci-dessus | voir ci-dessus | voir ci-dessus |\n",
    "\n",
    "### Interpr√©tation des m√©triques\n",
    "\n",
    "- **R¬≤ Score**: Proportion de la variance expliqu√©e par le mod√®le (1 = parfait)\n",
    "- **MAE**: Erreur moyenne en valeur absolue (en tonnes par hectare)\n",
    "- **RMSE**: Erreur quadratique moyenne (p√©nalise plus les grosses erreurs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
